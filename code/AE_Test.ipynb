{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Installations\\Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/200], loss:0.1157, MSE_loss:0.0363\n",
      "epoch [2/200], loss:0.0862, MSE_loss:0.0261\n",
      "epoch [3/200], loss:0.0709, MSE_loss:0.0214\n",
      "epoch [4/200], loss:0.0645, MSE_loss:0.0192\n",
      "epoch [5/200], loss:0.0542, MSE_loss:0.0159\n",
      "epoch [6/200], loss:0.0538, MSE_loss:0.0159\n",
      "epoch [7/200], loss:0.0546, MSE_loss:0.0161\n",
      "epoch [8/200], loss:0.0542, MSE_loss:0.0160\n",
      "epoch [9/200], loss:0.0512, MSE_loss:0.0151\n",
      "epoch [10/200], loss:0.0499, MSE_loss:0.0145\n",
      "epoch [11/200], loss:0.0467, MSE_loss:0.0138\n",
      "epoch [12/200], loss:0.0431, MSE_loss:0.0125\n",
      "epoch [13/200], loss:0.0425, MSE_loss:0.0126\n",
      "epoch [14/200], loss:0.0424, MSE_loss:0.0124\n",
      "epoch [15/200], loss:0.0386, MSE_loss:0.0112\n",
      "epoch [16/200], loss:0.0431, MSE_loss:0.0126\n",
      "epoch [17/200], loss:0.0426, MSE_loss:0.0123\n",
      "epoch [18/200], loss:0.0381, MSE_loss:0.0112\n",
      "epoch [19/200], loss:0.0373, MSE_loss:0.0108\n",
      "epoch [20/200], loss:0.0402, MSE_loss:0.0118\n",
      "epoch [21/200], loss:0.0368, MSE_loss:0.0106\n",
      "epoch [22/200], loss:0.0386, MSE_loss:0.0113\n",
      "epoch [23/200], loss:0.0342, MSE_loss:0.0098\n",
      "epoch [24/200], loss:0.0413, MSE_loss:0.0120\n",
      "epoch [25/200], loss:0.0335, MSE_loss:0.0096\n",
      "epoch [26/200], loss:0.0350, MSE_loss:0.0100\n",
      "epoch [27/200], loss:0.0385, MSE_loss:0.0111\n",
      "epoch [28/200], loss:0.0358, MSE_loss:0.0102\n",
      "epoch [29/200], loss:0.0355, MSE_loss:0.0102\n",
      "epoch [30/200], loss:0.0340, MSE_loss:0.0099\n",
      "epoch [31/200], loss:0.0331, MSE_loss:0.0095\n",
      "epoch [32/200], loss:0.0334, MSE_loss:0.0096\n",
      "epoch [33/200], loss:0.0359, MSE_loss:0.0104\n",
      "epoch [34/200], loss:0.0361, MSE_loss:0.0102\n",
      "epoch [35/200], loss:0.0300, MSE_loss:0.0086\n",
      "epoch [36/200], loss:0.0311, MSE_loss:0.0089\n",
      "epoch [37/200], loss:0.0286, MSE_loss:0.0082\n",
      "epoch [38/200], loss:0.0307, MSE_loss:0.0088\n",
      "epoch [39/200], loss:0.0313, MSE_loss:0.0090\n",
      "epoch [40/200], loss:0.0302, MSE_loss:0.0085\n",
      "epoch [41/200], loss:0.0286, MSE_loss:0.0082\n",
      "epoch [42/200], loss:0.0298, MSE_loss:0.0084\n",
      "epoch [43/200], loss:0.0294, MSE_loss:0.0085\n",
      "epoch [44/200], loss:0.0316, MSE_loss:0.0092\n",
      "epoch [45/200], loss:0.0296, MSE_loss:0.0085\n",
      "epoch [46/200], loss:0.0305, MSE_loss:0.0088\n",
      "epoch [47/200], loss:0.0314, MSE_loss:0.0090\n",
      "epoch [48/200], loss:0.0283, MSE_loss:0.0081\n",
      "epoch [49/200], loss:0.0280, MSE_loss:0.0080\n",
      "epoch [50/200], loss:0.0287, MSE_loss:0.0082\n",
      "epoch [51/200], loss:0.0282, MSE_loss:0.0078\n",
      "epoch [52/200], loss:0.0321, MSE_loss:0.0092\n",
      "epoch [53/200], loss:0.0299, MSE_loss:0.0086\n",
      "epoch [54/200], loss:0.0299, MSE_loss:0.0086\n",
      "epoch [55/200], loss:0.0283, MSE_loss:0.0081\n",
      "epoch [56/200], loss:0.0280, MSE_loss:0.0080\n",
      "epoch [57/200], loss:0.0266, MSE_loss:0.0075\n",
      "epoch [58/200], loss:0.0282, MSE_loss:0.0080\n",
      "epoch [59/200], loss:0.0265, MSE_loss:0.0077\n",
      "epoch [60/200], loss:0.0278, MSE_loss:0.0079\n",
      "epoch [61/200], loss:0.0283, MSE_loss:0.0081\n",
      "epoch [62/200], loss:0.0259, MSE_loss:0.0073\n",
      "epoch [63/200], loss:0.0310, MSE_loss:0.0090\n",
      "epoch [64/200], loss:0.0276, MSE_loss:0.0078\n",
      "epoch [65/200], loss:0.0296, MSE_loss:0.0085\n",
      "epoch [66/200], loss:0.0299, MSE_loss:0.0084\n",
      "epoch [67/200], loss:0.0301, MSE_loss:0.0085\n",
      "epoch [68/200], loss:0.0288, MSE_loss:0.0083\n",
      "epoch [69/200], loss:0.0256, MSE_loss:0.0073\n",
      "epoch [70/200], loss:0.0270, MSE_loss:0.0078\n",
      "epoch [71/200], loss:0.0261, MSE_loss:0.0074\n",
      "epoch [72/200], loss:0.0270, MSE_loss:0.0077\n",
      "epoch [73/200], loss:0.0282, MSE_loss:0.0081\n",
      "epoch [74/200], loss:0.0278, MSE_loss:0.0080\n",
      "epoch [75/200], loss:0.0275, MSE_loss:0.0078\n",
      "epoch [76/200], loss:0.0268, MSE_loss:0.0077\n",
      "epoch [77/200], loss:0.0246, MSE_loss:0.0070\n",
      "epoch [78/200], loss:0.0259, MSE_loss:0.0074\n",
      "epoch [79/200], loss:0.0269, MSE_loss:0.0076\n",
      "epoch [80/200], loss:0.0270, MSE_loss:0.0077\n",
      "epoch [81/200], loss:0.0293, MSE_loss:0.0083\n",
      "epoch [82/200], loss:0.0287, MSE_loss:0.0081\n",
      "epoch [83/200], loss:0.0288, MSE_loss:0.0081\n",
      "epoch [84/200], loss:0.0275, MSE_loss:0.0078\n",
      "epoch [85/200], loss:0.0283, MSE_loss:0.0081\n",
      "epoch [86/200], loss:0.0278, MSE_loss:0.0080\n",
      "epoch [87/200], loss:0.0266, MSE_loss:0.0076\n",
      "epoch [88/200], loss:0.0272, MSE_loss:0.0076\n",
      "epoch [89/200], loss:0.0249, MSE_loss:0.0072\n",
      "epoch [90/200], loss:0.0273, MSE_loss:0.0077\n",
      "epoch [91/200], loss:0.0260, MSE_loss:0.0073\n",
      "epoch [92/200], loss:0.0270, MSE_loss:0.0076\n",
      "epoch [93/200], loss:0.0243, MSE_loss:0.0068\n",
      "epoch [94/200], loss:0.0252, MSE_loss:0.0071\n",
      "epoch [95/200], loss:0.0301, MSE_loss:0.0084\n",
      "epoch [96/200], loss:0.0271, MSE_loss:0.0077\n",
      "epoch [97/200], loss:0.0272, MSE_loss:0.0077\n",
      "epoch [98/200], loss:0.0262, MSE_loss:0.0073\n",
      "epoch [99/200], loss:0.0242, MSE_loss:0.0068\n",
      "epoch [100/200], loss:0.0240, MSE_loss:0.0069\n",
      "epoch [101/200], loss:0.0261, MSE_loss:0.0073\n",
      "epoch [102/200], loss:0.0242, MSE_loss:0.0069\n",
      "epoch [103/200], loss:0.0279, MSE_loss:0.0080\n",
      "epoch [104/200], loss:0.0230, MSE_loss:0.0065\n",
      "epoch [105/200], loss:0.0253, MSE_loss:0.0072\n",
      "epoch [106/200], loss:0.0249, MSE_loss:0.0070\n",
      "epoch [107/200], loss:0.0249, MSE_loss:0.0070\n",
      "epoch [108/200], loss:0.0273, MSE_loss:0.0077\n",
      "epoch [109/200], loss:0.0271, MSE_loss:0.0077\n",
      "epoch [110/200], loss:0.0260, MSE_loss:0.0072\n",
      "epoch [111/200], loss:0.0278, MSE_loss:0.0078\n",
      "epoch [112/200], loss:0.0255, MSE_loss:0.0072\n",
      "epoch [113/200], loss:0.0267, MSE_loss:0.0076\n",
      "epoch [114/200], loss:0.0272, MSE_loss:0.0078\n",
      "epoch [115/200], loss:0.0237, MSE_loss:0.0068\n",
      "epoch [116/200], loss:0.0236, MSE_loss:0.0067\n",
      "epoch [117/200], loss:0.0291, MSE_loss:0.0082\n",
      "epoch [118/200], loss:0.0264, MSE_loss:0.0075\n",
      "epoch [119/200], loss:0.0246, MSE_loss:0.0069\n",
      "epoch [120/200], loss:0.0263, MSE_loss:0.0074\n",
      "epoch [121/200], loss:0.0274, MSE_loss:0.0078\n",
      "epoch [122/200], loss:0.0236, MSE_loss:0.0067\n",
      "epoch [123/200], loss:0.0242, MSE_loss:0.0067\n",
      "epoch [124/200], loss:0.0232, MSE_loss:0.0065\n",
      "epoch [125/200], loss:0.0223, MSE_loss:0.0063\n",
      "epoch [126/200], loss:0.0248, MSE_loss:0.0071\n",
      "epoch [127/200], loss:0.0206, MSE_loss:0.0057\n",
      "epoch [128/200], loss:0.0249, MSE_loss:0.0070\n",
      "epoch [129/200], loss:0.0243, MSE_loss:0.0069\n",
      "epoch [130/200], loss:0.0265, MSE_loss:0.0075\n",
      "epoch [131/200], loss:0.0263, MSE_loss:0.0074\n",
      "epoch [132/200], loss:0.0280, MSE_loss:0.0078\n",
      "epoch [133/200], loss:0.0262, MSE_loss:0.0075\n",
      "epoch [134/200], loss:0.0266, MSE_loss:0.0075\n",
      "epoch [135/200], loss:0.0278, MSE_loss:0.0078\n",
      "epoch [136/200], loss:0.0277, MSE_loss:0.0079\n",
      "epoch [137/200], loss:0.0252, MSE_loss:0.0072\n",
      "epoch [138/200], loss:0.0265, MSE_loss:0.0076\n",
      "epoch [139/200], loss:0.0242, MSE_loss:0.0069\n",
      "epoch [140/200], loss:0.0251, MSE_loss:0.0071\n",
      "epoch [141/200], loss:0.0235, MSE_loss:0.0065\n",
      "epoch [142/200], loss:0.0251, MSE_loss:0.0069\n",
      "epoch [143/200], loss:0.0265, MSE_loss:0.0074\n",
      "epoch [144/200], loss:0.0249, MSE_loss:0.0069\n",
      "epoch [145/200], loss:0.0224, MSE_loss:0.0063\n",
      "epoch [146/200], loss:0.0246, MSE_loss:0.0070\n",
      "epoch [147/200], loss:0.0276, MSE_loss:0.0077\n",
      "epoch [148/200], loss:0.0245, MSE_loss:0.0068\n",
      "epoch [149/200], loss:0.0261, MSE_loss:0.0074\n",
      "epoch [150/200], loss:0.0248, MSE_loss:0.0071\n",
      "epoch [151/200], loss:0.0250, MSE_loss:0.0071\n",
      "epoch [152/200], loss:0.0221, MSE_loss:0.0063\n",
      "epoch [153/200], loss:0.0231, MSE_loss:0.0065\n",
      "epoch [154/200], loss:0.0253, MSE_loss:0.0073\n",
      "epoch [155/200], loss:0.0254, MSE_loss:0.0071\n",
      "epoch [156/200], loss:0.0238, MSE_loss:0.0067\n",
      "epoch [157/200], loss:0.0239, MSE_loss:0.0068\n",
      "epoch [158/200], loss:0.0247, MSE_loss:0.0069\n",
      "epoch [159/200], loss:0.0253, MSE_loss:0.0071\n",
      "epoch [160/200], loss:0.0248, MSE_loss:0.0070\n",
      "epoch [161/200], loss:0.0267, MSE_loss:0.0075\n",
      "epoch [162/200], loss:0.0246, MSE_loss:0.0069\n",
      "epoch [163/200], loss:0.0240, MSE_loss:0.0067\n",
      "epoch [164/200], loss:0.0259, MSE_loss:0.0074\n",
      "epoch [165/200], loss:0.0240, MSE_loss:0.0068\n",
      "epoch [166/200], loss:0.0233, MSE_loss:0.0066\n",
      "epoch [167/200], loss:0.0240, MSE_loss:0.0067\n",
      "epoch [168/200], loss:0.0223, MSE_loss:0.0064\n",
      "epoch [169/200], loss:0.0244, MSE_loss:0.0069\n",
      "epoch [170/200], loss:0.0274, MSE_loss:0.0076\n",
      "epoch [171/200], loss:0.0233, MSE_loss:0.0066\n",
      "epoch [172/200], loss:0.0249, MSE_loss:0.0071\n",
      "epoch [173/200], loss:0.0237, MSE_loss:0.0067\n",
      "epoch [174/200], loss:0.0265, MSE_loss:0.0075\n",
      "epoch [175/200], loss:0.0254, MSE_loss:0.0072\n",
      "epoch [176/200], loss:0.0248, MSE_loss:0.0069\n",
      "epoch [177/200], loss:0.0259, MSE_loss:0.0073\n",
      "epoch [178/200], loss:0.0260, MSE_loss:0.0072\n",
      "epoch [179/200], loss:0.0233, MSE_loss:0.0065\n",
      "epoch [180/200], loss:0.0249, MSE_loss:0.0071\n",
      "epoch [181/200], loss:0.0258, MSE_loss:0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [182/200], loss:0.0264, MSE_loss:0.0075\n",
      "epoch [183/200], loss:0.0252, MSE_loss:0.0071\n",
      "epoch [184/200], loss:0.0226, MSE_loss:0.0063\n",
      "epoch [185/200], loss:0.0237, MSE_loss:0.0068\n",
      "epoch [186/200], loss:0.0229, MSE_loss:0.0064\n",
      "epoch [187/200], loss:0.0223, MSE_loss:0.0065\n",
      "epoch [188/200], loss:0.0232, MSE_loss:0.0066\n",
      "epoch [189/200], loss:0.0255, MSE_loss:0.0072\n",
      "epoch [190/200], loss:0.0234, MSE_loss:0.0065\n",
      "epoch [191/200], loss:0.0231, MSE_loss:0.0066\n",
      "epoch [192/200], loss:0.0255, MSE_loss:0.0073\n",
      "epoch [193/200], loss:0.0266, MSE_loss:0.0076\n",
      "epoch [194/200], loss:0.0240, MSE_loss:0.0067\n",
      "epoch [195/200], loss:0.0233, MSE_loss:0.0066\n",
      "epoch [196/200], loss:0.0221, MSE_loss:0.0062\n",
      "epoch [197/200], loss:0.0229, MSE_loss:0.0064\n",
      "epoch [198/200], loss:0.0243, MSE_loss:0.0069\n",
      "epoch [199/200], loss:0.0218, MSE_loss:0.0061\n",
      "epoch [200/200], loss:0.0221, MSE_loss:0.0062\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 28, 28)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "#         print(img)\n",
    "#         print(img.size())\n",
    "#         print('--------------------------')\n",
    "        img = img.view(img.size(0), -1)\n",
    "#         print(img)\n",
    "#         print(img.size())\n",
    "#         print('--------------------------')\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "        #MIDIMG=model.encoder(img).view(img.size(0),8,8).cpu().detach().numpy()\n",
    "        #MIDIMG=MIDIMG[0]\n",
    "        #MIDIMG=np.rint(MIDIMG/np.sum(MIDIMG)*255)\n",
    "        #print(MIDIMG)\n",
    "        #plt.imshow(MIDIMG)\n",
    "        #plt.show()\n",
    "        loss = criterion(output, img)\n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data[0], MSE_loss.data[0]))\n",
    "    if epoch % 20 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        save_image(x, './mlp_img/x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './mlp_img/x_hat_{}.png'.format(epoch))\n",
    "\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoded IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Installations\\Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\ipykernel_launcher.py:105: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/2], loss:0.1117, MSE_loss:0.0345\n",
      "epoch [2/2], loss:0.0845, MSE_loss:0.0257\n",
      "[[ 0.  0.  0.  9.  4.  0.  0.  0.]\n",
      " [ 9.  5.  1.  2. 10. 12.  0.  0.]\n",
      " [ 0.  5.  5.  6.  8.  5.  8. 12.]\n",
      " [ 7.  2.  0.  0.  9.  0.  3.  9.]\n",
      " [ 9.  0.  5.  0.  0.  0.  0.  5.]\n",
      " [ 7.  0.  6.  3.  8. 10.  6.  6.]\n",
      " [ 6.  3.  7.  0.  1.  0.  2.  8.]\n",
      " [ 4.  5.  0.  0.  4.  0. 10.  6.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23e8f66be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.exists('./mlp_img'):\n",
    "    os.mkdir('./mlp_img')\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "num_epochs = 2\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "def plot_sample_img(img, name):\n",
    "    img = img.view(1, 28, 28)\n",
    "    save_image(img, './sample_{}.png'.format(name))\n",
    "\n",
    "\n",
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])\n",
    "\n",
    "dataset = MNIST('./data', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28 * 28),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = autoencoder().cuda()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        img, _ = data\n",
    "#         print(img)\n",
    "#         print(img.size())\n",
    "#         print('--------------------------')\n",
    "        img = img.view(img.size(0), -1)\n",
    "#         print(img)\n",
    "#         print(img.size())\n",
    "#         print('--------------------------')\n",
    "        img = Variable(img).cuda()\n",
    "        # ===================forward=====================\n",
    "        output = model(img)\n",
    "#         MIDIMG=model.encoder(img).view(img.size(0),8,8).cpu().detach().numpy()\n",
    "#         MIDIMG=MIDIMG[0]\n",
    "#         MIDIMG=np.rint(MIDIMG/np.sum(MIDIMG)*255)\n",
    "#         print(MIDIMG)\n",
    "#         plt.imshow(MIDIMG)\n",
    "#         plt.show()\n",
    "        loss = criterion(output, img)\n",
    "        MSE_loss = nn.MSELoss()(output, img)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # ===================log========================\n",
    "    print('epoch [{}/{}], loss:{:.4f}, MSE_loss:{:.4f}'\n",
    "          .format(epoch + 1, num_epochs, loss.data[0], MSE_loss.data[0]))\n",
    "    if epoch % 20 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        save_image(x, './mlp_img/x_{}.png'.format(epoch))\n",
    "        save_image(x_hat, './mlp_img/x_hat_{}.png'.format(epoch))\n",
    "        \n",
    "        \n",
    "MIDIMG=model.encoder(img).view(img.size(0),8,8).cpu().detach().numpy()\n",
    "MIDIMG=MIDIMG[0]\n",
    "MIDIMG=np.rint(MIDIMG/np.sum(MIDIMG)*255)\n",
    "print(MIDIMG)\n",
    "plt.imshow(MIDIMG)\n",
    "plt.show()\n",
    "torch.save(model.state_dict(), './sim_autoencoder.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
